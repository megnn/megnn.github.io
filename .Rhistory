#Test each version of the stepCols
maxspec = 0
removeCol = ""
for(i in stepCols1){
newcols = c(stepCols1,attritionSplitTrain[,])
newcols = newcols[!is.na(newcols)]
fitAttrition = naiveBayes(attritionSplitTrain[,newcols], as.factor(attritionSplitTrain$Attrition), laplace = 1, data = attritionSplitTrain)
attritionPredict = predict(fitAttrition, attritionSplitTest[,newcols])
cm = confusionMatrix(table(attritionPredict, attritionSplitTest$Attrition ))
spec = cm$byClass[2]
if(spec > maxspec){
maxspec = spec
removeCol = i
}
}
#Balanced KNN Model
trueYes = attritionFullTrain %>% filter(Attrition == "Yes")
trueNo = attritionFullTrain %>% filter(Attrition == "No")
indicesNo = sample(seq(1:dim(trueNo)[1]), round(dim(trueYes)[1]))
trueNoSample = trueNo[indicesNo,]
balancedTotal = rbind(trueYes, trueNoSample)
percentage = .8
indices = sample(seq(1:dim(balancedTotal)[1]), round(dim(balancedTotal)[1]*percentage))
balancedSplitTrain = balancedTotal[indices,]
balancedSplitTest = balancedTotal[-indices,]
#step based cols w/out char
knnColsStep = c("Age", "EnvironmentSatisfaction", "JobInvolvement", "JobSatisfaction",
"NumCompaniesWorked", "RelationshipSatisfaction", "TotalWorkingYears",
"WorkLifeBalance","YearsInCurrentRole", "YearsSinceLastPromotion","logMonthlyIncome")
#Balanced KNN predict based on limited data set.
Balanceknnpredict = knn(balancedSplitTrain[,knnColsStep], attritionSplitTest[,knnColsStep], balancedSplitTrain$Attrition, k = 5)
confusionMatrix(table(Balanceknnpredict,attritionSplitTest$Attrition))
#Simple KNN
simpleknnCols = c("Age", "JobInvolvement", "JobSatisfaction","TotalWorkingYears",
"WorkLifeBalance","YearsInCurrentRole", "YearsSinceLastPromotion","logMonthlyIncome")
simpleKnnPredict = knn(attritionSplitTrain[,simpleknnCols], attritionSplitTest[,simpleknnCols], attritionSplitTrain$Attrition, k = 5)
confusionMatrix(table(simpleKnnPredict,attritionSplitTest$Attrition))
ensembleDF = data.frame(NB = attritionPredict, BKNN = Balanceknnpredict, SKNN = simpleKnnPredict)
for(i in seq(1:dim(ensembleDF)[1])){
score = 0
if(ensembleDF[i,1] == "Yes"){
score = score + 2
}
if(ensembleDF[i,2] == "Yes"){
score = score + 2
}
if(ensembleDF[i,3] == "Yes"){
score = score + 0
}
if(score > 1.5 ){
ensembleDF$ensemblePredictions[i] = "Yes"
}
else{ensembleDF$ensemblePredictions[i] = "No"}
}
table(ensembleDF$ensemblePredictions,attritionSplitTest$Attrition)
confusionMatrix(table(ensembleDF$ensemblePredictions,attritionSplitTest$Attrition))
ensembleDF = data.frame(NB = attritionPredict, KNN = Balanceknnpredict)
for(i in seq(1:dim(ensembleDF)[1])){
score = 0
if(ensembleDF[i,1] == "Yes" | ensembleDF[i,2] == "Yes"){
ensembleDF$ensemblePredictions[i] = "Yes"
}
else{ensembleDF$ensemblePredictions[i] = "No"}
}
table(ensembleDF$ensemblePredictions,attritionSplitTest$Attrition)
confusionMatrix(table(ensembleDF$ensemblePredictions,attritionSplitTest$Attrition))
percentage = .8
indices = sample(seq(1:dim(attritionFullTrain)[1]), round(dim(attritionFullTrain)[1]*percentage))
attritionSplitTrain = attritionFullTrain[indices,]
attritionSplitTest = attritionFullTrain[-indices,]
#knnTrain = splitTrain %>% select(c("MonthlyIncome", "JobSatisfaction", "JobLevel"))
#knnTest = splitTest %>% select(c( "MonthlyIncome", "JobSatisfaction", "JobLevel"))
#years in current role > years since last promotion
#Do not include environment satisfaction, TrainingTimesLastYear
#log the monthly income.
#Overtime good.
#Building a Faux Linear Model for Attrition,
#library(MASS)
#full.model <- lm(Attrition_Yes ~., data = trainCodedNoChar )
#Stepwise Var Selection
#step.model <- stepAIC(full.model, direction = "both",  trace = FALSE)
#summary(step.model)
stepCols = c("Age", "DistanceFromHome", "EnvironmentSatisfaction", "JobInvolvement", "JobSatisfaction",
"NumCompaniesWorked", "RelationshipSatisfaction", "TotalWorkingYears", "TrainingTimesLastYear",
"WorkLifeBalance","YearsInCurrentRole", "YearsSinceLastPromotion", "BusinessTravel",
"EducationField", "JobRole", "MaritalStatus","OverTime")
stepCols1 = c("Age", "EnvironmentSatisfaction", "JobInvolvement", "JobSatisfaction",
"NumCompaniesWorked", "RelationshipSatisfaction", "TotalWorkingYears",
"WorkLifeBalance","YearsInCurrentRole", "YearsSinceLastPromotion", "BusinessTravel",
"JobRole", "MaritalStatus","OverTime", "logMonthlyIncome")
fitAttrition = naiveBayes(attritionSplitTrain[,stepCols1], as.factor(attritionSplitTrain$Attrition), laplace = 1, data = attritionSplitTrain)
attritionPredict = predict(fitAttrition, attritionSplitTest[,stepCols1])
confusionMatrix(table(attritionPredict, attritionSplitTest$Attrition ))
#Test each version of the stepCols
maxspec = 0
removeCol = ""
for(i in stepCols1){
newcols = c(stepCols1,attritionSplitTrain[,])
newcols = newcols[!is.na(newcols)]
fitAttrition = naiveBayes(attritionSplitTrain[,newcols], as.factor(attritionSplitTrain$Attrition), laplace = 1, data = attritionSplitTrain)
attritionPredict = predict(fitAttrition, attritionSplitTest[,newcols])
cm = confusionMatrix(table(attritionPredict, attritionSplitTest$Attrition ))
spec = cm$byClass[2]
if(spec > maxspec){
maxspec = spec
removeCol = i
}
}
#Balanced KNN Model
trueYes = attritionFullTrain %>% filter(Attrition == "Yes")
trueNo = attritionFullTrain %>% filter(Attrition == "No")
indicesNo = sample(seq(1:dim(trueNo)[1]), round(dim(trueYes)[1]))
trueNoSample = trueNo[indicesNo,]
balancedTotal = rbind(trueYes, trueNoSample)
percentage = .8
indices = sample(seq(1:dim(balancedTotal)[1]), round(dim(balancedTotal)[1]*percentage))
balancedSplitTrain = balancedTotal[indices,]
balancedSplitTest = balancedTotal[-indices,]
#step based cols w/out char
knnColsStep = c("Age", "EnvironmentSatisfaction", "JobInvolvement", "JobSatisfaction",
"NumCompaniesWorked", "RelationshipSatisfaction", "TotalWorkingYears",
"WorkLifeBalance","YearsInCurrentRole", "YearsSinceLastPromotion","logMonthlyIncome")
#Balanced KNN predict based on limited data set.
Balanceknnpredict = knn(balancedSplitTrain[,knnColsStep], attritionSplitTest[,knnColsStep], balancedSplitTrain$Attrition, k = 5)
confusionMatrix(table(Balanceknnpredict,attritionSplitTest$Attrition))
ensembleDF = data.frame(NB = attritionPredict, KNN = Balanceknnpredict)
for(i in seq(1:dim(ensembleDF)[1])){
score = 0
if(ensembleDF[i,1] == "Yes" | ensembleDF[i,2] == "Yes"){
ensembleDF$ensemblePredictions[i] = "Yes"
}
else{ensembleDF$ensemblePredictions[i] = "No"}
}
table(ensembleDF$ensemblePredictions,attritionSplitTest$Attrition)
confusionMatrix(table(ensembleDF$ensemblePredictions,attritionSplitTest$Attrition))
cm$overall
cm$byClass
df = data.frame(sens = "", spec = "", nrows = 1000)
dim(df)
for(i in seq(1:10)){
percentage = .8
indices = sample(seq(1:dim(attritionFullTrain)[1]), round(dim(attritionFullTrain)[1]*percentage))
attritionSplitTrain = attritionFullTrain[indices,]
attritionSplitTest = attritionFullTrain[-indices,]
#knnTrain = splitTrain %>% select(c("MonthlyIncome", "JobSatisfaction", "JobLevel"))
#knnTest = splitTest %>% select(c( "MonthlyIncome", "JobSatisfaction", "JobLevel"))
#years in current role > years since last promotion
#Do not include environment satisfaction, TrainingTimesLastYear
#log the monthly income.
#Overtime good.
stepCols = c("Age", "DistanceFromHome", "EnvironmentSatisfaction", "JobInvolvement", "JobSatisfaction",
"NumCompaniesWorked", "RelationshipSatisfaction", "TotalWorkingYears", "TrainingTimesLastYear",
"WorkLifeBalance","YearsInCurrentRole", "YearsSinceLastPromotion", "BusinessTravel",
"EducationField", "JobRole", "MaritalStatus","OverTime")
stepCols1 = c("Age", "EnvironmentSatisfaction", "JobInvolvement", "JobSatisfaction",
"NumCompaniesWorked", "RelationshipSatisfaction", "TotalWorkingYears",
"WorkLifeBalance","YearsInCurrentRole", "YearsSinceLastPromotion", "BusinessTravel",
"JobRole", "MaritalStatus","OverTime", "logMonthlyIncome")
fitAttrition = naiveBayes(attritionSplitTrain[,stepCols1], as.factor(attritionSplitTrain$Attrition), laplace = 1, data = attritionSplitTrain)
attritionPredict = predict(fitAttrition, attritionSplitTest[,stepCols1])
#confusionMatrix(table(attritionPredict, attritionSplitTest$Attrition ))
#Balanced KNN Model
trueYes = attritionFullTrain %>% filter(Attrition == "Yes")
trueNo = attritionFullTrain %>% filter(Attrition == "No")
indicesNo = sample(seq(1:dim(trueNo)[1]), round(dim(trueYes)[1]))
trueNoSample = trueNo[indicesNo,]
balancedTotal = rbind(trueYes, trueNoSample)
percentage = .8
indices = sample(seq(1:dim(balancedTotal)[1]), round(dim(balancedTotal)[1]*percentage))
balancedSplitTrain = balancedTotal[indices,]
balancedSplitTest = balancedTotal[-indices,]
#step based cols w/out char
knnColsStep = c("Age", "EnvironmentSatisfaction", "JobInvolvement", "JobSatisfaction",
"NumCompaniesWorked", "RelationshipSatisfaction", "TotalWorkingYears",
"WorkLifeBalance","YearsInCurrentRole", "YearsSinceLastPromotion","logMonthlyIncome")
#Balanced KNN predict based on limited data set.
Balanceknnpredict = knn(balancedSplitTrain[,knnColsStep], attritionSplitTest[,knnColsStep], balancedSplitTrain$Attrition, k = 5)
#confusionMatrix(table(Balanceknnpredict,attritionSplitTest$Attrition))
ensembleDF = data.frame(NB = attritionPredict, KNN = Balanceknnpredict)
for(i in seq(1:dim(ensembleDF)[1])){
score = 0
if(ensembleDF[i,1] == "Yes" | ensembleDF[i,2] == "Yes"){
ensembleDF$ensemblePredictions[i] = "Yes"
}
else{ensembleDF$ensemblePredictions[i] = "No"}
}
table(ensembleDF$ensemblePredictions,attritionSplitTest$Attrition)
cm = confusionMatrix(table(ensembleDF$ensemblePredictions,attritionSplitTest$Attrition))
df$sens[i] = cm$byClass[1]
df$spec[i] = cm$byClass[2]
}
df = data.frame(sens = "", spec = "", nrows = 1000)
source('~/data/MSDSR/6306/FinalProject/TestingAttritionSampling.R')
source('~/data/MSDSR/6306/FinalProject/TestingAttritionSampling.R')
min(sens)
sens
cm$byClass
source('~/data/MSDSR/6306/FinalProject/TestingAttritionSampling.R')
sens
source('~/data/MSDSR/6306/FinalProject/TestingAttritionSampling.R')
sense
sens
sens = list()
spec = list()
source('~/data/MSDSR/6306/FinalProject/TestingAttritionSampling.R')
sens
cm$byClass[1]
source('~/data/MSDSR/6306/FinalProject/TestingAttritionSampling.R')
sens
source('~/data/MSDSR/6306/FinalProject/TestingAttritionSampling.R')
sens
min(sens)
spec
source('~/data/MSDSR/6306/FinalProject/TestingAttritionSampling.R')
source('~/data/MSDSR/6306/FinalProject/TestingAttritionSampling.R')
sens
min(sens)
min(sens[])
sens
cm
cm$byClass
typeof(cm$byClass)
typeof(cm$byClass[1])
cm$byClass[1][0]
cm$byClass[1]
debugSource('~/data/MSDSR/6306/FinalProject/TestingAttritionSampling.R')
source('~/data/MSDSR/6306/FinalProject/TestingAttritionSampling.R')
sens
max(sens)
typeof(sens)
typeof(sens[1])
typeof(sens[1][1])
typeof(sens[1][2])
typeof(sens[1[1]])
typeof(sens[1[1[1]]])
typeof(sens[1[1[1[1]]]])
sens
sens[0]
sens[0][0]
sens[0][0][0]
sens[0][0][0][0]
sens[1]
sens[0]
sens[1]
sens[1][1]
sens[1][2]
sens[-1]
sens[-1000]
sens[-31133]
sens[1]
sens[1][1]
sens[1]
typeof(sens[1])
typeof(sens[1][1])
sens[1]
sens[1][1]
(sens[1])[1]
cm$byClass[1]
typeof(cm$byClass[1])
cm$byClass[1]["Sensitivity"]
uname(cm$byClass[1])
unname(cm$byClass[1])
unname(cm$byClass[1])[1]
unname(cm$byClass[1])
x = unname(cm$byClass[1])
x[1]
x[1][1]
typeof(x)
source('~/data/MSDSR/6306/FinalProject/TestingAttritionSampling.R')
sens
typeof(sens[1])
?unname
sens[j] = unname(cm$byClass[1], force = TRUE)
source('~/data/MSDSR/6306/FinalProject/TestingAttritionSampling.R')
sens
max(sens)
typeof(sens[[1]])
typeof(sens[1])
?minn38
?min
min(unlist(sense))
min(unlist(sens))
source('~/data/MSDSR/6306/FinalProject/TestingAttritionSampling.R')
min(unlist(sens))
min(unlist(spec))
boxplot(sens)
boxplot(spec)
hist(sens)
hist(unlist(sens))
hist(unlist(spec))
view(sens)
source('~/data/MSDSR/6306/FinalProject/TestingAttritionSampling.R')
cm
summary(step.model)
?knn
hist(sens, main = "Frequency of Sensitivities", xlab = "Sensitivity")
hist(unlist(sens), main = "Frequency of Sensitivities", xlab = "Sensitivity")
library(tidyverse)
library(GGally)
library(fastDummies)
library(caret)
library(e1071)
train = read_csv("/Users/zmartygirl/data/MSDSR/6306/FinalProject/CaseStudy2-data.csv")
nosalaryTest = read_csv("/Users/zmartygirl/data/MSDSR/6306/FinalProject/CaseStudy2CompSet No Salary.csv")
noattritionTest = read.csv("/Users/zmartygirl/data/MSDSR/6306/FinalProject/CaseStudy2CompSet No Attrition.csv")
#Splitting the Data into 80/20 to train and test the model
#Coding character variables as 0 or 1 and removing them from ds.
#This data set can be used if we need numeric variables for everything
trainCoded = dummy_cols(train, select_columns = c( "Attrition", "BusinessTravel", "Department", "EducationField", "Gender", "JobRole", "MaritalStatus", "Over18", "OverTime"), remove_first_dummy = TRUE)
trainCodedNoChar = trainCoded %>% select(-c( "Attrition", "BusinessTravel", "Department", "EducationField", "Gender", "JobRole", "MaritalStatus", "Over18", "OverTime"))
fitSalaryfinal
fitSalaryfinal = lm(MonthlyIncome ~ TotalWorkingYears + Age  + JobLevel + JobRole  , splitTrain)
predictSalaryfinal = predict(fitSalaryfinal, splitTest)
predictSalaryfinal
resid(predictSalaryfinal)
summary(predictSalaryfinal)
modelCV = data.frame(R2 = R2(predictSalaryfinal, splitTest$MonthlyIncome), RMSE =  RMSE(predictSalaryfinal, splitTest$MonthlyIncome), MAE = MAE(predictSalaryfinal, splitTest$MonthlyIncome))
modelCV
plot( predictSalaryfinal ~ splitTest$MonthlyIncome)
modelDF = data.frame(Predicted = predictSalaryfinal, True = splitTest$MonthlyIncome, Residuals = (predictSalaryfinal-splitTest$MonthlyIncome))
plot(modelDF$Residuals)
plot(modelDF$Residuals~ splitTest$Age)
plot(modelDF$Residuals~ splitTest$DailyRate)
plot(modelDF$Residuals~ splitTest$JobRole)
plot(modelDF$Residuals~ splitTest$JobInvolvement)
plot(modelDF$Residuals~ splitTest$JobSatisfaction)
plot(modelDF$Residuals~ splitTest$MonthlyIncome)
plot(splitTest$MonthlyIncome)
plot(modelDF$Residuals~ splitTest$MonthlyIncome)
plot(modelDF$Predicted ~ modelDF$True)
modelDF %>% ggplot(aes(x = True, y = Predicted)) + geom_point() + ggtitle("Predicted by True")
modelDF %>% ggplot(aes(y = Residuals)) + geom_point() + ggtitle("Residuals")
modelDF %>% ggplot(aes(x = True, y = Residuals)) + geom_point() + ggtitle("Residuals")
modelDF %>% ggplot(aes(x = n(), y = Residuals)) + geom_point() + ggtitle("Residuals")
modelDF %>% ggplot(aes(x = Index, y = Residuals)) + geom_point() + ggtitle("Residuals")
modelDF = data.frame(Predicted = predictSalaryfinal, True = splitTest$MonthlyIncome, Residuals = (predictSalaryfinal-splitTest$MonthlyIncome), Index = seq(1:dim(splitTest)[1]))
modelDF %>% ggplot(aes(x = Index,y = Residuals)) + geom_point() + ggtitle("Residuals")
view(train)
fitSalaryfinal = lm(MonthlyIncome ~ TotalWorkingYears + Age  + JobLevel + JobRole + Education , splitTrain)
predictSalaryfinal = predict(fitSalaryfinal, splitTest)
modelCV = data.frame(R2 = R2(predictSalaryfinal, splitTest$MonthlyIncome), RMSE =  RMSE(predictSalaryfinal, splitTest$MonthlyIncome), MAE = MAE(predictSalaryfinal, splitTest$MonthlyIncome))
modelCV
fitSalaryfinal = lm(MonthlyIncome ~ TotalWorkingYears + Age  + JobLevel + JobRole + JobSatisfaction , splitTrain)
predictSalaryfinal = predict(fitSalaryfinal, splitTest)
modelCV = data.frame(R2 = R2(predictSalaryfinal, splitTest$MonthlyIncome), RMSE =  RMSE(predictSalaryfinal, splitTest$MonthlyIncome), MAE = MAE(predictSalaryfinal, splitTest$MonthlyIncome))
modelCV
fitSalaryfinal = lm(MonthlyIncome ~ TotalWorkingYears + Age  + JobLevel + JobRole + JobSatisfaction + MonthlyRate , splitTrain)
predictSalaryfinal = predict(fitSalaryfinal, splitTest)
modelCV = data.frame(R2 = R2(predictSalaryfinal, splitTest$MonthlyIncome), RMSE =  RMSE(predictSalaryfinal, splitTest$MonthlyIncome), MAE = MAE(predictSalaryfinal, splitTest$MonthlyIncome))
modelCV
fitSalaryfinal = lm(MonthlyIncome ~ TotalWorkingYears + Age  + JobLevel + JobRole + JobSatisfaction + MonthlyRate + HourlyRate + DailyRate, splitTrain)
predictSalaryfinal = predict(fitSalaryfinal, splitTest)
modelCV = data.frame(R2 = R2(predictSalaryfinal, splitTest$MonthlyIncome), RMSE =  RMSE(predictSalaryfinal, splitTest$MonthlyIncome), MAE = MAE(predictSalaryfinal, splitTest$MonthlyIncome))
modelCV
fitSalaryfinal = lm(MonthlyIncome ~ TotalWorkingYears + Age  + JobLevel + JobRole + JobSatisfaction + MonthlyRate + HourlyRate , splitTrain)
predictSalaryfinal = predict(fitSalaryfinal, splitTest)
modelCV = data.frame(R2 = R2(predictSalaryfinal, splitTest$MonthlyIncome), RMSE =  RMSE(predictSalaryfinal, splitTest$MonthlyIncome), MAE = MAE(predictSalaryfinal, splitTest$MonthlyIncome))
modelCV
fitSalaryfinal = lm(MonthlyIncome ~ TotalWorkingYears + Age  + JobLevel + JobRole + JobSatisfaction + HourlyRate + DailyRate, splitTrain)
predictSalaryfinal = predict(fitSalaryfinal, splitTest)
modelCV = data.frame(R2 = R2(predictSalaryfinal, splitTest$MonthlyIncome), RMSE =  RMSE(predictSalaryfinal, splitTest$MonthlyIncome), MAE = MAE(predictSalaryfinal, splitTest$MonthlyIncome))
modelCV
fitSalaryfinal = lm(MonthlyIncome ~ TotalWorkingYears + Age  + JobLevel + JobRole + JobSatisfaction + MonthlyRate + HourlyRate + DailyRate + Department, splitTrain)
predictSalaryfinal = predict(fitSalaryfinal, splitTest)
modelCV = data.frame(R2 = R2(predictSalaryfinal, splitTest$MonthlyIncome), RMSE =  RMSE(predictSalaryfinal, splitTest$MonthlyIncome), MAE = MAE(predictSalaryfinal, splitTest$MonthlyIncome))
modelCV
percentage = .8
indices = sample(seq(1:dim(train)[1]), round(dim(train)[1]*percentage))
splitTrain = train[indices,]
splitTest = train[-indices,]
fitSalaryfinal = lm(MonthlyIncome ~ TotalWorkingYears + Age  + JobLevel + JobRole + JobSatisfaction + MonthlyRate + HourlyRate + DailyRate + Department, splitTrain)
predictSalaryfinal = predict(fitSalaryfinal, splitTest)
modelCV = data.frame(R2 = R2(predictSalaryfinal, splitTest$MonthlyIncome), RMSE =  RMSE(predictSalaryfinal, splitTest$MonthlyIncome), MAE = MAE(predictSalaryfinal, splitTest$MonthlyIncome))
modelCV
fitSalaryfinal = lm(MonthlyIncome ~ TotalWorkingYears + Age  + JobLevel + JobRole + JobSatisfaction + MonthlyRate, splitTrain)
predictSalaryfinal = predict(fitSalaryfinal, splitTest)
modelCV = data.frame(R2 = R2(predictSalaryfinal, splitTest$MonthlyIncome), RMSE =  RMSE(predictSalaryfinal, splitTest$MonthlyIncome), MAE = MAE(predictSalaryfinal, splitTest$MonthlyIncome))
modelCV
fitSalaryfinal = lm(MonthlyIncome ~ TotalWorkingYears + Age  + JobLevel + JobRole + JobSatisfaction + MonthlyRate + EnvironmentSatisfaction, splitTrain)
predictSalaryfinal = predict(fitSalaryfinal, splitTest)
modelCV = data.frame(R2 = R2(predictSalaryfinal, splitTest$MonthlyIncome), RMSE =  RMSE(predictSalaryfinal, splitTest$MonthlyIncome), MAE = MAE(predictSalaryfinal, splitTest$MonthlyIncome))
modelCV
fitSalaryfinal = lm(MonthlyIncome ~ TotalWorkingYears + Age  + JobLevel + JobRole + JobSatisfaction + MonthlyRate + RelationshipSatisfaction, splitTrain)
predictSalaryfinal = predict(fitSalaryfinal, splitTest)
modelCV = data.frame(R2 = R2(predictSalaryfinal, splitTest$MonthlyIncome), RMSE =  RMSE(predictSalaryfinal, splitTest$MonthlyIncome), MAE = MAE(predictSalaryfinal, splitTest$MonthlyIncome))
modelCV
modelCV
fitSalaryfinal = lm(MonthlyIncome ~ TotalWorkingYears + Age  + JobLevel + JobRole + JobSatisfaction + MonthlyRate + RelationshipSatisfaction, splitTrain)
predictSalaryfinal = predict(fitSalaryfinal, splitTest)
modelCV = data.frame(R2 = R2(predictSalaryfinal, splitTest$MonthlyIncome), RMSE =  RMSE(predictSalaryfinal, splitTest$MonthlyIncome), MAE = MAE(predictSalaryfinal, splitTest$MonthlyIncome))
modelCV
fitSalaryfinal = lm(MonthlyIncome ~ TotalWorkingYears + Age  + JobLevel + JobRole + JobSatisfaction + MonthlyRate + Gender, splitTrain)
predictSalaryfinal = predict(fitSalaryfinal, splitTest)
modelCV = data.frame(R2 = R2(predictSalaryfinal, splitTest$MonthlyIncome), RMSE =  RMSE(predictSalaryfinal, splitTest$MonthlyIncome), MAE = MAE(predictSalaryfinal, splitTest$MonthlyIncome))
modelCV
modelDF %>% ggplot(aes(x = True, y = Predicted)) + geom_point() + ggtitle("Predicted by True")
modelDF = data.frame(Predicted = predictSalaryfinal, True = splitTest$MonthlyIncome, Residuals = (predictSalaryfinal-splitTest$MonthlyIncome), Index = seq(1:dim(splitTest)[1]))
modelDF %>% ggplot(aes(x = True, y = Predicted)) + geom_point() + ggtitle("Predicted by True")
plot(splitTest$MonthlyIncome)
fitSalaryfinal = lm(MonthlyIncome ~ TotalWorkingYears + Age  + JobRole + JobSatisfaction + MonthlyRate + Gender, splitTrain)
predictSalaryfinal = predict(fitSalaryfinal, splitTest)
modelCV = data.frame(R2 = R2(predictSalaryfinal, splitTest$MonthlyIncome), RMSE =  RMSE(predictSalaryfinal, splitTest$MonthlyIncome), MAE = MAE(predictSalaryfinal, splitTest$MonthlyIncome))
modelCV
confusionMatrix(table(attritionPredict, attritionSplitTest$Attrition ))
Balanceknnpredict = knn(balancedSplitTrain[,knnColsStep], attritionSplitTest[,knnColsStep], balancedSplitTrain$Attrition, k = 5)
confusionMatrix(table(Balanceknnpredict,attritionSplitTest$Attrition))
cm
SalaryFitPrediction = lm(MonthlyIncome ~ TotalWorkingYears + Age  + JobLevel + JobRole + JobSatisfaction + MonthlyRate + Gender, train)
predictSalaryfinal = predict(SalaryFitPrediction, nosalaryTest)
predictSalaryfinal
plot(predictSalaryfinal)
boxplot(predictSalaryfinal)
SalaryPredictions = data.frame(ID = nosalaryTest$ID, MonthlyIncome = predictSalaryfinal)
SalaryPredictions %>% ggplot(aes(x = predictSalaryfinal)) + geom_boxplot() + ggtitle()
SalaryPredictions = data.frame(ID = nosalaryTest$ID, MonthlyIncome = predictSalaryfinal)
SalaryPredictions %>% ggplot(aes(x = predictSalaryfinal)) + geom_boxplot() + ggtitle("Distribution of Salary Predictions")
SalaryPredictions %>% ggplot(aes(y = predictSalaryfinal)) + geom_boxplot() + ggtitle("Distribution of Salary Predictions")
SalaryPredictions %>% ggplot(aes(y = MonthlyIncome)) + geom_boxplot() + ggtitle("Distribution of Salary Predictions") + ylab("Monthly Income")
boxplot(train$MonthlyIncome)
trueYes = attritionFullTrain %>% filter(Attrition == "Yes")
trueNo = attritionFullTrain %>% filter(Attrition == "No")
indicesNo = sample(seq(1:dim(trueNo)[1]), round(dim(trueYes)[1]))
trueNoSample = trueNo[indicesNo,]
balancedTotal = rbind(trueYes, trueNoSample)
#Balanced KNN predict based on limited data set.
Balanceknnpredict = knn(balancedTotal[,knnColsStep], noattritionTest[,knnColsStep], balancedTotal$Attrition, k = 5)
ensembleDF = data.frame(NB = attritionPredict, KNN = Balanceknnpredict)
for(i in seq(1:dim(ensembleDF)[1])){
score = 0
if(ensembleDF[i,1] == "Yes" | ensembleDF[i,2] == "Yes"){
ensembleDF$ensemblePredictions[i] = "Yes"
}
else{ensembleDF$ensemblePredictions[i] = "No"}
}
ensembleDF
table(ensembleDF)
table(ensembleDF$ensemblePredictions)
67/107
67+107
67/174
dim(SalaryPredictions)
trueYes = attritionFullTrain %>% filter(Attrition == "Yes")
trueNo = attritionFullTrain %>% filter(Attrition == "No")
indicesNo = sample(seq(1:dim(trueNo)[1]), round(dim(trueYes)[1]))
trueNoSample = trueNo[indicesNo,]
balancedTotal = rbind(trueYes, trueNoSample)
#Balanced KNN predict based on limited data set.
KnnPrediction = knn(balancedTotal[,knnColsStep], noattritionTest[,knnColsStep], balancedTotal$Attrition, k = 5)
ensembleDF = data.frame(NB = NBPrediction, KNN = KnnPrediction)
for(i in seq(1:dim(ensembleDF)[1])){
score = 0
if(ensembleDF[i,1] == "Yes" | ensembleDF[i,2] == "Yes"){
ensembleDF$ensemblePredictions[i] = "Yes"
}
else{ensembleDF$ensemblePredictions[i] = "No"}
}
table(ensembleDF$ensemblePredictions)
dim(ensembleDF)
dim(noattritionTest)
dim(balancedTotal)
dim(KnnPrediction)
KnnPrediction = knn(balancedTotal[,knnColsStep], noattritionTest[,knnColsStep], balancedTotal$Attrition, k = 5)
knnColsStep = c("Age", "EnvironmentSatisfaction", "JobInvolvement", "JobSatisfaction",
"NumCompaniesWorked", "RelationshipSatisfaction", "TotalWorkingYears",
"WorkLifeBalance","YearsInCurrentRole", "YearsSinceLastPromotion","logMonthlyIncome")
noattritionTest  = noattritionTest %>% mutate(logMonthlyIncome = log(MonthlyIncome))
fitAttrition = naiveBayes(attritionFullTrain[,stepCols1], as.factor(attritionFullTrain$Attrition),  laplace = 1, data = attritionFullTrain)
NBPrediction = predict(fitAttrition, noattritionTest[,stepCols1])
#Balanced KNN Model
trueYes = attritionFullTrain %>% filter(Attrition == "Yes")
trueNo = attritionFullTrain %>% filter(Attrition == "No")
indicesNo = sample(seq(1:dim(trueNo)[1]), round(dim(trueYes)[1]))
trueNoSample = trueNo[indicesNo,]
balancedTotal = rbind(trueYes, trueNoSample)
knnColsStep = c("Age", "EnvironmentSatisfaction", "JobInvolvement", "JobSatisfaction",
"NumCompaniesWorked", "RelationshipSatisfaction", "TotalWorkingYears",
"WorkLifeBalance","YearsInCurrentRole", "YearsSinceLastPromotion","logMonthlyIncome")
#Balanced KNN predict based on limited data set.
KnnPrediction = knn(balancedTotal[,knnColsStep], noattritionTest[,knnColsStep], balancedTotal$Attrition, k = 5)
ensembleDF = data.frame(NB = NBPrediction, KNN = KnnPrediction)
for(i in seq(1:dim(ensembleDF)[1])){
score = 0
if(ensembleDF[i,1] == "Yes" | ensembleDF[i,2] == "Yes"){
ensembleDF$ensemblePredictions[i] = "Yes"
}
else{ensembleDF$ensemblePredictions[i] = "No"}
}
table(ensembleDF$ensemblePredictions)
112+188
112/300
modelCV
fitSalaryfinal = lm(MonthlyIncome ~ TotalWorkingYears + Age  + JobLevel + JobRole + JobSatisfaction + MonthlyRate + Gender, splitTrain)
predictSalaryfinal = predict(fitSalaryfinal, splitTest)
modelCV = data.frame(R2 = R2(predictSalaryfinal, splitTest$MonthlyIncome), RMSE =  RMSE(predictSalaryfinal, splitTest$MonthlyIncome), MAE = MAE(predictSalaryfinal, splitTest$MonthlyIncome))
modelCV
write.csv(ensembleDF,"Case2Predictions Riley Attrition.csv")
write.csv(SalaryPredictions,"Case2Predictions Riley Salary.csv")
getwd()
AttritionPredictions = data.frame(noattritionTest$ID, ensembleDF$ensemblePredictions)
AttritionPredictions
write.csv(AttritionPredictions,"Case2Predictions Riley Attrition.csv")
write.csv(SalaryPredictions,"Case2Predictions Riley Salary.csv")
getwd()
setwd("/Users/zmartygirl/data/megnn.github.io")
library(rmarkdown)
render_site()
render_site()
render_site()
render_site()
render_site()
render_site()
render_site()
